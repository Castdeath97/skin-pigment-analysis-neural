{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Report-Introduction\" data-toc-modified-id=\"Report-Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Report Introduction</a></span></li><li><span><a href=\"#Background\" data-toc-modified-id=\"Background-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Background</a></span></li><li><span><a href=\"#Modeling-Assumptions-and-Potential-Issues\" data-toc-modified-id=\"Modeling-Assumptions-and-Potential-Issues-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Modeling Assumptions and Potential Issues</a></span></li><li><span><a href=\"#Test-design\" data-toc-modified-id=\"Test-design-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Test design</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-the-Testing-and-Training-Datasets\" data-toc-modified-id=\"Creating-the-Testing-and-Training-Datasets-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Creating the Testing and Training Datasets</a></span><ul class=\"toc-item\"><li><span><a href=\"#One-Hot-Encoding-and-Minor-Manipulation\" data-toc-modified-id=\"One-Hot-Encoding-and-Minor-Manipulation-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>One Hot Encoding and Minor Manipulation</a></span></li><li><span><a href=\"#Test-Split-and-Scaling\" data-toc-modified-id=\"Test-Split-and-Scaling-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Test Split and Scaling</a></span></li></ul></li><li><span><a href=\"#Measurements\" data-toc-modified-id=\"Measurements-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Measurements</a></span></li></ul></li><li><span><a href=\"#Models-Description-and-Assessments\" data-toc-modified-id=\"Models-Description-and-Assessments-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Models Description and Assessments</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Construction-and-Tuning\" data-toc-modified-id=\"Construction-and-Tuning-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Construction and Tuning</a></span></li><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Interpretation</a></span></li><li><span><a href=\"#Assessment\" data-toc-modified-id=\"Assessment-5.1.4\"><span class=\"toc-item-num\">5.1.4&nbsp;&nbsp;</span>Assessment</a></span></li></ul></li><li><span><a href=\"#Support-Vector-Machines-(SVM)\" data-toc-modified-id=\"Support-Vector-Machines-(SVM)-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Support Vector Machines (SVM)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Construction-and-Tuning\" data-toc-modified-id=\"Construction-and-Tuning-5.2.2\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;</span>Construction and Tuning</a></span></li><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-5.2.3\"><span class=\"toc-item-num\">5.2.3&nbsp;&nbsp;</span>Interpretation</a></span></li><li><span><a href=\"#Detailed-assessment\" data-toc-modified-id=\"Detailed-assessment-5.2.4\"><span class=\"toc-item-num\">5.2.4&nbsp;&nbsp;</span>Detailed assessment</a></span></li></ul></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Random Forest</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Construction-and-Tuning\" data-toc-modified-id=\"Construction-and-Tuning-5.3.2\"><span class=\"toc-item-num\">5.3.2&nbsp;&nbsp;</span>Construction and Tuning</a></span></li><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-5.3.3\"><span class=\"toc-item-num\">5.3.3&nbsp;&nbsp;</span>Interpretation</a></span></li><li><span><a href=\"#Assessment\" data-toc-modified-id=\"Assessment-5.3.4\"><span class=\"toc-item-num\">5.3.4&nbsp;&nbsp;</span>Assessment</a></span></li></ul></li></ul></li><li><span><a href=\"#Summary-of-Modelling\" data-toc-modified-id=\"Summary-of-Modelling-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Summary of Modelling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fitting-Times\" data-toc-modified-id=\"Fitting-Times-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Fitting Times</a></span></li><li><span><a href=\"#Prediction-Times\" data-toc-modified-id=\"Prediction-Times-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Prediction Times</a></span></li><li><span><a href=\"#Accuracy\" data-toc-modified-id=\"Accuracy-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Accuracy</a></span></li><li><span><a href=\"#F1-Scores\" data-toc-modified-id=\"F1-Scores-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>F1 Scores</a></span></li><li><span><a href=\"#Summary-of-Model-Assessment\" data-toc-modified-id=\"Summary-of-Model-Assessment-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>Summary of Model Assessment</a></span></li></ul></li><li><span><a href=\"#Evaluation-of-Data-Mining-Process\" data-toc-modified-id=\"Evaluation-of-Data-Mining-Process-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Evaluation of Data Mining Process</a></span><ul class=\"toc-item\"><li><span><a href=\"#Business-Success-Criteria-and-Future-Work\" data-toc-modified-id=\"Business-Success-Criteria-and-Future-Work-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Business Success Criteria and Future Work</a></span></li><li><span><a href=\"#Techniques-and-Tools\" data-toc-modified-id=\"Techniques-and-Tools-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Techniques and Tools</a></span></li></ul></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"tocSkip\"><center class=\"tocSkip\">Modelling and Evaluation Report</center></h1>\n",
    "<h1 class=\"tocSkip\"><center class=\"tocSkip\"><i class=\"tocSkip\">Ammar Hasan 150454388</i></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npandas.core.series.Series: Lesion types (text) series sorted by idx for labels\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as met\n",
    "\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "BASE_PROCESSED_DATA_DIR = '../data/processed'\n",
    "\"\"\"\n",
    "str: Base processed data directory\n",
    "\"\"\"\n",
    "\n",
    "PROCESSED_CSV_FILE = BASE_PROCESSED_DATA_DIR + '/processed.csv'\n",
    "\"\"\"\n",
    "str: HAM1000_metadata.csv metadata file location \n",
    "\"\"\"\n",
    "        \n",
    "# Read dataset in\n",
    "skin_df = pd.read_csv(PROCESSED_CSV_FILE, index_col=0)\n",
    "\"\"\"\n",
    "pandas.core.frame.DataFrame: final dataset\n",
    "\"\"\"\n",
    "\n",
    "def printMetrics(prediction, y_test):\n",
    "    \"\"\"\n",
    "    Prints accuracy, confusion and F1 metrics\n",
    "    \n",
    "    returns list of accuracy, confusion and F1 metrics\n",
    "    \"\"\"\n",
    "    accuracy = met.accuracy_score(y_test, prediction)\n",
    "    confusion = met.confusion_matrix(y_test, prediction)\n",
    "    f1_score_avg = met.f1_score(y_test, prediction, average='weighted')\n",
    "    f1_score = met.f1_score(y_test, prediction, average= None)\n",
    "\n",
    "    print('accuracy', accuracy)\n",
    "    print()\n",
    "    print(confusion)\n",
    "    print()\n",
    "    print('f1 average: ', f1_score_avg)\n",
    "    print('f1: ', f1_score)\n",
    "\n",
    "    return([accuracy, confusion, f1_score_avg])\n",
    "\n",
    "lesion_type_label = skin_df[\n",
    "    ['lesion_type_idx', 'lesion_type']].sort_values(\n",
    "    'lesion_type_idx').drop_duplicates()['lesion_type']\n",
    "\"\"\"\n",
    "pandas.core.series.Series: Lesion types (text) series sorted by idx for labels\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Introduction\n",
    "\n",
    "This report documents the process of creating neural networks to model skin pigment diagnosis and the evaluation of said models (especially compared to other methods used in the previous analysis). Two types of neural networks will be created:\n",
    "\n",
    "* Basic Sequential neural network\n",
    "* Convoluted neural network\n",
    "\n",
    "#### One Hot Encoding and Minor Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical cols using one hot encoding\n",
    "\n",
    "one_hot_localization = pd.get_dummies(skin_df['localization'])\n",
    "one_hot_localization.drop('unknown', axis=1, inplace = True)\n",
    "\n",
    "one_hot_sex = pd.get_dummies(skin_df['sex'])\n",
    "one_hot_sex.drop('unknown', axis=1, inplace = True)\n",
    "\n",
    "# Drop old categorical cols and replace with new ones\n",
    "# drop dx type (not needed beyond data understanding)\n",
    "\n",
    "skin_df.drop(['dx_type', 'localization', 'sex'], axis = 1, inplace = True)\n",
    "\n",
    "# Join the encoded dfs\n",
    "\n",
    "skin_df = skin_df.join(one_hot_localization)\n",
    "skin_df = skin_df.join(one_hot_sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas dummies for categorical variables, localization values are one hot coded using new columns for every value (0 false / 1 true), however one of the columns is dropped since a negation of all the other columns represents it. Lastly, the now redundant sex and localization fields are dropped alongside dx_type (no need for analysing diagnosis type beyond Data Understanding).\n",
    "\n",
    "#### Test Split and Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  del sys.path[0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and test data in a 50-50 split\n",
    "# Don't include lesion_types (used for response) and image path (not used yet)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    skin_df.drop(['lesion_type_idx', 'lesion_type'], axis=1),\n",
    "    skin_df['lesion_type_idx'], test_size=0.5, random_state=0)\n",
    "\n",
    "# scale using a partial fit for speed\n",
    "\n",
    "scaling = StandardScaler()\n",
    "\n",
    "scaling.partial_fit(X_test)\n",
    "X_test = scaling.transform(X_test)\n",
    "\n",
    "scaling.partial_fit(X_train)\n",
    "X_train = scaling.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data and the testing data are separated using a 50-50 split respectively, both sets consist of a set of predictors (X) and a response (y). The predictor data has the lesion_type_idx and lesion_type fields removed since they can leak the ground truth. For the response data only the lesion_type_idx field is used since it is sufficient at representing the category of skin lesion (the response / what is being predicted).\n",
    "\n",
    "To ensure that the impact of predictors is not effected by the measurement scale - which could occur in this dataset due to the variety of predictors - the predictors are scaled using a scaling transform (i.e. with default mean and standard deviation transform).\n",
    "\n",
    "### Measurements\n",
    "\n",
    "The computer used to carry the measurements has the following specifications:\n",
    "* CPU: i7-7700HQ\n",
    "* RAM: 8GB\n",
    "* OS: Windows 10\n",
    "* GPU: GTX 1060 (notebook)\n",
    "\n",
    "To evaluate the model the following measurements are taken:\n",
    "* Fit time: Using the time python library, a timer is started and stopped to measure tuning and fit .\n",
    "* Prediction time: Using the time python library, a timer is started and stopped to measure the prediction.\n",
    "* Confusion matrix: Using the sklearn metrics library a confusion matrix is printed.\n",
    "* F1 Score: Using the sklearn metrics library a F1 score is calculated using weighted averages and for every class.\n",
    "\n",
    "## Models Description and Assessments\n",
    "\n",
    "### Neural Networks\n",
    "\n",
    "Neural networks are machine learning tools that are inspired by human brain biology, relying on multiple connected neurons that interact with one another through multiple layers. Neural networks emphasize the importance of interaction between features more so than traditional models reliant on basic sums of coefficients attached to predictors.\n",
    "\t\t\t\t\n",
    "#### Sequential Neural Network\n",
    "\n",
    "##### Introduction \t\t\n",
    "\n",
    "Sequential Neural Networks layers are sequentially attached meaning each layer's neurons only attach to the next layer's. The networks will use relu activation (softmax at final layer) and Adam optimisation using categorical cross entropy loss. The model training will early stop if no improvement occurs after 3 iterations.\n",
    "\n",
    "##### Construction and Tuning \n",
    "\n",
    "To tune the networks multiple models of increasing complexity/capacity (various widths and/or layer counts) are created and the ones with the best performance are picked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to separate targets\n",
    "target = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq_model(hidden_layers, nodes_per_layer) :\n",
    "    \"\"\"\n",
    "    creates a sequential neural networks with a set of hidden \n",
    "    layers (hidden_layers) with a given number of nodes (nodes_per_layer)\n",
    "    which is complied in a 0.3 validation split in 20 epochs (early stop 3)\n",
    "    \n",
    "    returns keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    early_stopping_monitor = EarlyStopping(patience = 3)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(hidden_layers - 1) :\n",
    "        if i == 0 :\n",
    "            model.add(Dense(nodes_per_layer, activation = 'relu', input_shape = (X_train.shape[1],)))\n",
    "        else :\n",
    "            model.add(Dense(nodes_per_layer, activation = 'relu'))\n",
    "            \n",
    "    model.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
    "                   metrics = ['accuracy'])\n",
    "    model.fit(X_train, target, validation_split = 0.3, epochs = 20,\n",
    "               callbacks = [early_stopping_monitor])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3504 samples, validate on 1503 samples\n",
      "Epoch 1/20\n",
      "3504/3504 [==============================] - 4s 1ms/step - loss: 1.9651 - acc: 0.4421 - val_loss: 1.7250 - val_acc: 0.4837\n",
      "Epoch 2/20\n",
      "3504/3504 [==============================] - 1s 166us/step - loss: 1.6573 - acc: 0.5097 - val_loss: 1.5512 - val_acc: 0.5143\n",
      "Epoch 3/20\n",
      "3504/3504 [==============================] - 1s 171us/step - loss: 1.4482 - acc: 0.5605 - val_loss: 1.5195 - val_acc: 0.5176\n",
      "Epoch 4/20\n",
      "3504/3504 [==============================] - 1s 176us/step - loss: 1.3312 - acc: 0.6033 - val_loss: 1.4418 - val_acc: 0.5436\n",
      "Epoch 5/20\n",
      "3504/3504 [==============================] - 1s 164us/step - loss: 1.2684 - acc: 0.6201 - val_loss: 1.3574 - val_acc: 0.5995\n",
      "Epoch 6/20\n",
      "3504/3504 [==============================] - 1s 164us/step - loss: 1.1513 - acc: 0.6447 - val_loss: 1.2472 - val_acc: 0.5981\n",
      "Epoch 7/20\n",
      "3504/3504 [==============================] - 1s 160us/step - loss: 1.0535 - acc: 0.6858 - val_loss: 1.2005 - val_acc: 0.6334\n",
      "Epoch 8/20\n",
      "3504/3504 [==============================] - 1s 161us/step - loss: 1.0450 - acc: 0.6872 - val_loss: 1.1254 - val_acc: 0.6467\n",
      "Epoch 9/20\n",
      "3504/3504 [==============================] - 1s 174us/step - loss: 0.9205 - acc: 0.7140 - val_loss: 1.2367 - val_acc: 0.6188\n",
      "Epoch 10/20\n",
      "3504/3504 [==============================] - 1s 174us/step - loss: 0.9478 - acc: 0.7095 - val_loss: 1.0310 - val_acc: 0.6733\n",
      "Epoch 11/20\n",
      "3504/3504 [==============================] - 1s 170us/step - loss: 0.8494 - acc: 0.7314 - val_loss: 1.0216 - val_acc: 0.6753\n",
      "Epoch 12/20\n",
      "3504/3504 [==============================] - 1s 170us/step - loss: 0.8028 - acc: 0.7557 - val_loss: 1.0463 - val_acc: 0.6720\n",
      "Epoch 13/20\n",
      "3504/3504 [==============================] - 1s 173us/step - loss: 0.7931 - acc: 0.7454 - val_loss: 1.0357 - val_acc: 0.6653\n",
      "Epoch 14/20\n",
      "3504/3504 [==============================] - 1s 173us/step - loss: 0.7252 - acc: 0.7751 - val_loss: 0.9638 - val_acc: 0.6966\n",
      "Epoch 15/20\n",
      "3504/3504 [==============================] - 1s 170us/step - loss: 0.7238 - acc: 0.7737 - val_loss: 0.9875 - val_acc: 0.6753\n",
      "Epoch 16/20\n",
      "3504/3504 [==============================] - 1s 163us/step - loss: 0.7057 - acc: 0.7686 - val_loss: 0.9331 - val_acc: 0.7006\n",
      "Epoch 17/20\n",
      "3504/3504 [==============================] - 1s 163us/step - loss: 0.6834 - acc: 0.7820 - val_loss: 1.0394 - val_acc: 0.6833\n",
      "Epoch 18/20\n",
      "3504/3504 [==============================] - 1s 162us/step - loss: 0.6792 - acc: 0.7791 - val_loss: 0.9978 - val_acc: 0.6893\n",
      "Epoch 19/20\n",
      "3504/3504 [==============================] - 1s 163us/step - loss: 0.6390 - acc: 0.7968 - val_loss: 0.9782 - val_acc: 0.6946\n",
      "Train on 3504 samples, validate on 1503 samples\n",
      "Epoch 1/20\n",
      "3504/3504 [==============================] - 1s 307us/step - loss: 1.0339 - acc: 0.6561 - val_loss: 0.9325 - val_acc: 0.6906\n",
      "Epoch 2/20\n",
      "3504/3504 [==============================] - 1s 212us/step - loss: 0.8695 - acc: 0.6981 - val_loss: 0.8542 - val_acc: 0.6999\n",
      "Epoch 3/20\n",
      "3504/3504 [==============================] - 1s 214us/step - loss: 0.8146 - acc: 0.7046 - val_loss: 0.9076 - val_acc: 0.7059\n",
      "Epoch 4/20\n",
      "3504/3504 [==============================] - 1s 206us/step - loss: 0.7481 - acc: 0.7357 - val_loss: 0.8157 - val_acc: 0.7166\n",
      "Epoch 5/20\n",
      "3504/3504 [==============================] - 1s 208us/step - loss: 0.6920 - acc: 0.7437 - val_loss: 0.8600 - val_acc: 0.6999\n",
      "Epoch 6/20\n",
      "3504/3504 [==============================] - 1s 209us/step - loss: 0.6617 - acc: 0.7491 - val_loss: 0.8707 - val_acc: 0.7159\n",
      "Epoch 7/20\n",
      "3504/3504 [==============================] - ETA: 0s - loss: 0.6169 - acc: 0.773 - 1s 207us/step - loss: 0.6206 - acc: 0.7717 - val_loss: 0.8861 - val_acc: 0.6687\n",
      "Train on 3504 samples, validate on 1503 samples\n",
      "Epoch 1/20\n",
      "3504/3504 [==============================] - 1s 354us/step - loss: 0.9901 - acc: 0.6547 - val_loss: 0.9058 - val_acc: 0.6673\n",
      "Epoch 2/20\n",
      "3504/3504 [==============================] - ETA: 0s - loss: 0.8644 - acc: 0.686 - 1s 226us/step - loss: 0.8651 - acc: 0.6872 - val_loss: 0.8730 - val_acc: 0.6946\n",
      "Epoch 3/20\n",
      "3504/3504 [==============================] - 1s 229us/step - loss: 0.8189 - acc: 0.7003 - val_loss: 0.8743 - val_acc: 0.6913\n",
      "Epoch 4/20\n",
      "3504/3504 [==============================] - 1s 232us/step - loss: 0.7837 - acc: 0.7115 - val_loss: 0.8443 - val_acc: 0.6993\n",
      "Epoch 5/20\n",
      "3504/3504 [==============================] - 1s 223us/step - loss: 0.7460 - acc: 0.7283 - val_loss: 0.8152 - val_acc: 0.7206\n",
      "Epoch 6/20\n",
      "3504/3504 [==============================] - 1s 227us/step - loss: 0.7106 - acc: 0.7394 - val_loss: 0.8364 - val_acc: 0.7139\n",
      "Epoch 7/20\n",
      "3504/3504 [==============================] - 1s 235us/step - loss: 0.6819 - acc: 0.7517 - val_loss: 0.8214 - val_acc: 0.7206\n",
      "Epoch 8/20\n",
      "3504/3504 [==============================] - 1s 228us/step - loss: 0.6430 - acc: 0.7660 - val_loss: 0.8429 - val_acc: 0.7179\n",
      "Train on 3504 samples, validate on 1503 samples\n",
      "Epoch 1/20\n",
      "3504/3504 [==============================] - 1s 403us/step - loss: 0.9824 - acc: 0.6515 - val_loss: 1.0086 - val_acc: 0.6806\n",
      "Epoch 2/20\n",
      "3504/3504 [==============================] - 1s 240us/step - loss: 0.8661 - acc: 0.6849 - val_loss: 0.8784 - val_acc: 0.6840\n",
      "Epoch 3/20\n",
      "3504/3504 [==============================] - 1s 247us/step - loss: 0.8161 - acc: 0.7058 - val_loss: 0.8421 - val_acc: 0.7099\n",
      "Epoch 4/20\n",
      "3504/3504 [==============================] - 1s 244us/step - loss: 0.7727 - acc: 0.7086 - val_loss: 0.8552 - val_acc: 0.7053\n",
      "Epoch 5/20\n",
      "3504/3504 [==============================] - 1s 254us/step - loss: 0.7163 - acc: 0.7320 - val_loss: 0.8278 - val_acc: 0.7092\n",
      "Epoch 6/20\n",
      "3504/3504 [==============================] - 1s 236us/step - loss: 0.6983 - acc: 0.7349 - val_loss: 0.8152 - val_acc: 0.7092\n",
      "Epoch 7/20\n",
      "3504/3504 [==============================] - 1s 250us/step - loss: 0.6550 - acc: 0.7514 - val_loss: 0.8378 - val_acc: 0.7232\n",
      "Epoch 8/20\n",
      "3504/3504 [==============================] - 1s 249us/step - loss: 0.6115 - acc: 0.7686 - val_loss: 0.8613 - val_acc: 0.7146\n",
      "Epoch 9/20\n",
      "3504/3504 [==============================] - 1s 241us/step - loss: 0.5689 - acc: 0.7880 - val_loss: 0.9745 - val_acc: 0.6919\n"
     ]
    }
   ],
   "source": [
    "nn_fit_start = time.time()\n",
    "nn_model_1 = create_seq_model(1, 30)\n",
    "nn_model_2 = create_seq_model(3, 85)\n",
    "nn_model_3 = create_seq_model(5, 70)\n",
    "nn_model_4 = create_seq_model(5, 150)\n",
    "nn_fit_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential NN fit time(seconds):  37.03731608390808\n"
     ]
    }
   ],
   "source": [
    "nn_fit_time = nn_fit_end - nn_fit_start\n",
    "print('Sequential NN fit time(seconds): ', nn_fit_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple neuron network of 5 layers and 70 nodes per layer seems to performing in a manner satisfactory manner and seems to be very fast to tune with a dedicated GPU. But generally all networks performed quite similarly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7140575079872205\n",
      "\n",
      "[[  35   35   54    0   24    8    1]\n",
      " [  31  119   54    0   50    5    0]\n",
      " [  20   36  273    0  189   19    0]\n",
      " [   9   13   20    0   20    2    0]\n",
      " [  10   71  169    0 3082   23    1]\n",
      " [  10    8  150    0  329   64    0]\n",
      " [   6    8    5    0   51    1    3]]\n",
      "\n",
      "f1 average:  0.6805242467856232\n",
      "f1:  [0.25179856 0.43351548 0.43264659 0.         0.86804675 0.18740849\n",
      " 0.07594937]\n",
      "Sequential NN prediction time(seconds):  0.661231517791748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# carry prediction with time measurements \n",
    "# while recording prediction\n",
    "\n",
    "nn_pred_start = time.time()\n",
    "prediction = nn_model_3.predict_classes(X_test)\n",
    "nn_pred_end = time.time()\n",
    "\n",
    "nn_met = printMetrics(prediction, y_test)\n",
    "nn_pred_time = nn_pred_end - nn_pred_start\n",
    "print('Sequential NN prediction time(seconds): ', nn_pred_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the a sequential neural network doesn't actually perform better than logistic regression while being slightly slower to fit. Perhaps an approach were we do not look at the picture pixel by pixel would help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convoluted Neural Network\n",
    "\n",
    "##### Introduction \t\t\n",
    "\n",
    "This type of sequential neural network makes use of filtering kernels to manually extract features out of an images to use them to find more complex class defining features (rather than looking at it pixel by pixel). Convoluted neural networks however need to work on higher dimensions and use a lot of parameters, hence pooling and flatten layers are needed.\n",
    "\n",
    "\n",
    "##### Construction and Tuning \n",
    "\n",
    "Again, to tune the networks multiple models of increasing complexity/capacity (various widths and/or layer counts) are created and the ones with the best performance are picked. We will try 1 layer 30 nodes, 1 layer 50 nodes, 2 layers 50 nodes. \n",
    "\n",
    "However, the actual images from the HMINST challenge will be loaded instead of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3153"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_model(hidden_layers, nodes_per_layer) :\n",
    "    \"\"\"\n",
    "    creates a convoluted neural networks with a set of hidden \n",
    "    layers (hidden_layers) with a given number of nodes (nodes_per_layer)\n",
    "    which is complied in a 0.3 validation split in 20 epochs (early stop 3)\n",
    "    \n",
    "    returns keras model\n",
    "    \"\"\"\n",
    "    early_stopping_monitor = EarlyStopping(patience = 3)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(hidden_layers - 1) :\n",
    "        if i == 0 :\n",
    "            model.add(Conv2D(nodes_per_layer, kernel_size = 3, activation = 'relu', \n",
    "                   input_shape = (X_train.shape[0], X_train.shape[1])))            \n",
    "        else :\n",
    "            model.add(Conv2D(nodes_per_layer, kernel_size = 3, activation = 'relu'))\n",
    "        model.add(MaxPool2D(2))\n",
    "\n",
    "    model.add(Flatten())   \n",
    "    model.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
    "                   metrics = ['accuracy'])\n",
    "    model.fit(X_train, target, validation_split = 0.3, epochs = 20,\n",
    "               callbacks = [early_stopping_monitor])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer flatten_2: expected min_ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-81fbf0a5c498>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcnn_fit_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcnn_model_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_conv_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcnn_model_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_conv_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m85\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcnn_model_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_conv_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcnn_model_4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_conv_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-9014d4204351>\u001b[0m in \u001b[0;36mcreate_conv_model\u001b[1;34m(hidden_layers, nodes_per_layer)\u001b[0m\n\u001b[0;32m     25\u001b[0m                    metrics = ['accuracy'])\n\u001b[0;32m     26\u001b[0m     model.fit(X_train, target, validation_split = 0.3, epochs = 20,\n\u001b[1;32m---> 27\u001b[1;33m                callbacks = [early_stopping_monitor])\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    675\u001b[0m             \u001b[1;31m# to match the value shapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[1;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[0;32m    587\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    325\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected min_ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    328\u001b[0m             \u001b[1;31m# Check dtype.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer flatten_2: expected min_ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "cnn_fit_start = time.time()\n",
    "cnn_model_1 = create_conv_model(1, 30)\n",
    "cnn_model_2 = create_conv_model(3, 85)\n",
    "cnn_model_3 = create_conv_model(5, 70)\n",
    "cnn_model_4 = create_conv_model(5, 150)\n",
    "cnn_fit_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_fit_time = cnn_fit_end - cnn_fit_start\n",
    "print('Sequential NN fit time(seconds): ', cnn_fit_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carry prediction with time measurements \n",
    "# while recording prediction\n",
    "\n",
    "cnn_pred_start = time.time()\n",
    "prediction = cnn_model_1.predict_classes(X_test)\n",
    "cnn_pred_end = time.time()\n",
    "\n",
    "cnn_met = printMetrics(prediction, y_test)\n",
    "cnn_pred_time = cnn_pred_end - cnn_pred_start\n",
    "print('Sequential NN prediction time(seconds): ', cnn_pred_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nList: model name labels used for plotting\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_labels = ['NN', 'CNN']\n",
    "\"\"\"\n",
    "List: model name labels used for plotting\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAGDCAYAAADgeTwhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xu8bWVZL/DfI2gamIhcQkQ2GpZWiMUpS1NK81aKlhlkSuY55Alvp9tBreOlKDt572KhknjDyDLx0hGjtDBNwQAvaBLXLSQbVEQwlO1z/phjxWS599pzscdca034fj+f+ZljvOMdYz5zr7X2/K13vWOM6u4AAAA77zbrXQAAANxSCNcAADAS4RoAAEYiXAMAwEiEawAAGIlwDQAAIxGugVusqtpUVV1Vu87Q9xeq6oyb8RpPrKrTVrnPc6vqtat9rVUc/+Sqeuy8jr9aVXX3qvpKVe0ywrGeWVUv3on9/7Sqfmtn6wDYHuEa2BCq6qKq+lpV7bWs/ewhIG9an8puEtK/MvU4J0m6+83d/bCpvl1V3zG1fnhVbZ4+Xnf/bnf/9znVekiS+yZ5x1TbQVX1gaq6Zvh3fvIOjjHzLyWz6O5Lunv37t46wuFOSPLzVbXP8g1TIX7p0VV17dT6j3T307r7t0eoA2CbhGtgI7kwyVFLK1X1vUnusH7lfJM9hpC4e3ffd72L2Y5fSvLmvukdwn43yUVJ9kxy/ySfWoe6RtHd/5nkb5N80y8IUyF+9+7efWi+71TbP61pscCtknANbCRvzE1D09FJ3jDdoaruVFVvqKotVXVxVf1mVd1m2LZLVb2kqq6sqguS/MQ29n1dVV1eVZ+rqt/Z2akK09NJquofh+ZzhpHSozMJgnedGj29a1W9oKreNOyzNEp8dFVdMtT+vKnj36GqTqqqL1bVeVX1G8tHwpd5ZJIPLGu7Icnm7v56d/9Hd5+5g7e19D6+NNT8Q9M1L6t712H9/VX121X1wWGE/LSlv0Kspu+w/cnD1/aqqvqtYbT9oVP1vT/LvrazqqrXV9XvDMuHV9Xm4d/0iuH74rFV9aiq+req+kJVPXdq39tU1XFV9e9DbadU1Z7DtttX1ZuG9i9V1Uerat+bUyOw2IRrYCP5cJJvq6p7D6H3Z5O8aVmfP0xypyT3SPLgTML4U4Zt/yPJTya5X5LDkjx+2b4nZRI0v2Po87Ako03P6O4HDYtLo6UnZRJ2L5saPb1sO7s/MMl3JnlIkv9TVfce2p+fZFMm7/fHk/z89l6/qnZLclCSzyzb9JEkv1ZVj5jxrSy9j6WR+g/NuN/PZfK12CfJ7ZL82mr7VtV9kvxJkicm2S+Tr/X+y/Y9L5OpL2P49iS3H17j/yR5TSb/xt+f5Ecy+VrcY+j7zCSPzeT77q5Jvpjkj4dtRw+1HpDkLkmeluSrI9UILBDhGtholkavfzzJp5N8bmnDVOB+Tndf090XJXlpkicNXZ6Q5BXdfWl3fyHJ703tu28mQffZ3X1td1+R5OVJjlxFbVcOo5JfqqqVguPN8cLu/mp3n5PknNwYHp+Q5He7+4vdvTnJq1Y4xh7D8zVLDVX1gCS/kskvEq+tqocP7QcPo+Q14nv48+7+t+7+apJTkhx6M/o+Psk7u/uM7v5aJoG3l+17TSZBdgxfT3J8d389yVuT7JXklcP31yeTfDLJIUPfX0ryvO7e3N3XJ3lBkscPI/JfzyRUf0d3b+3us7r7yyPVCCyQUU5WARjRGzOZlnBQlk0JyST43C7JxVNtF+fGkc27Jrl02bYlBya5bZLLp/LkbZb135G9uvuGVfRfjf+YWr4uydKc4eXvaaV6vzQ83zHJfw7LT0/yxu7+QFU9Lsm7q+pJmYzYnr5sbvbO2t57WE3fm7zf7r6uqq5atu8dk1y9E3VOu2rqRMulkebPT23/6lRtByZ5e1V9Y2r71iT7ZvJ9e0CSt1bVHpn8xeV5Q2gHbkWEa2BD6e6Lq+rCJI9K8tRlm6/MZITwwNx4Ut7dc+Po9uWZBJxMbVtyaZLrM9+AvC07G14vT3K33Ph+D9hex+6+tqr+Pcm9kmwZmnfNZCpMuvujVXVkkr/OZErDY1ZR87VJvnVq/dtnfQOrdHkm02OSTOacZzIiPO3emYzur7VLk/xid39wO9tfmOSFNbmyzXsymZ7zurUpDdgoTAsBNqKnJvmx7r52unEYYTwlyfFVdceqOjCTKQ9L87JPSfLMqrpbVd05yXFT+16e5LQkL62qbxtOTrtnVT145No/n8n86On1u1TVzZ3GcEqS51TVnatq/0xGolfynkzmBC/5y0z+TR5UkxM/L8/kyiH7ZjKSvy1bknwjN30fZyd5UE0ud3enJM9Z9TuZzduSPLqqfriqbpdJYF0+deXBmZwoutb+NJPvvQOTpKr2rqojhuUfrarvHaYufTmTXwLHuPQgsGCEa2DD6e5/X+GKFs/IZBT1giRnJHlLkhOHba9J8t5MRjU/lskI7bQnZzKt5FOZjNy+LZOT5sb0giQnDfOyn9Ddn05ycpILhra7rvJ4L0qyOZPLFP5dJjVfv0L/E5I8cWkudXefkskvGSdkMm3k5Ezmmv96kndV1d2XH6C7r0tyfJIPDjXfv7vfl+Qvkpyb5Kwk71rl+5jJMM/5GZnMf748k/nVV2R4z1V1+0z+qnHSPF5/B16Z5NQkp1XVNZmcgPuDw7Zvz+Rr8+VMTrj8QL75ZFzgVqDGnW4HwDxV1f9McmR3b3fEvarekuSU7v6btatsPqpq90x+KTi4uy+sqmckOaC7f2OdSwPYJuEaYAOrqv0ymZ7xoSQHJ3l3kj/q7lesa2FzVFWPTnJ6JtNBXprJ6PD3jXzyJcBcmBYCsLHdLsmfZTI94u8zua35n6xrRfN3RJLLhsfBmYzUC9bAQjByDQAAIzFyDQAAIxGuAQBgJAt9E5m99tqrN23atN5lAABwC3fWWWdd2d1776jfQofrTZs25cwzt3cpXAAAGEdVXTxLP9NCAABgJMI1AACMRLgGAICRCNcAADAS4RoAAEYiXAMAwEiEawAAGIlwDQAAIxGuAQBgJMI1AACMRLgGAICRCNcAADAS4RoAAEay63oXAACsvU3HvXu9S4BVu+jFP7HeJeyQkWsAABiJcA0AACMRrgEAYCTCNQAAjES4BgCAkQjXAAAwEuEaAABGIlwDAMBIhGsAABjJ3MJ1VR1QVf9QVedV1Ser6llD+wuq6nNVdfbweNTUPs+pqvOr6jNV9fB51QYAAPMwz9uf35DkV7v7Y1V1xyRnVdX7hm0v7+6XTHeuqvskOTLJdye5a5K/q6p7dffWOdYIAACjmdvIdXdf3t0fG5avSXJekv1X2OWIJG/t7uu7+8Ik5yf5gXnVBwAAY1uTOddVtSnJ/ZL8y9D09Ko6t6pOrKo7D237J7l0arfN2UYYr6pjqurMqjpzy5Ytc6waAABWZ+7huqp2T/JXSZ7d3V9O8uok90xyaJLLk7x0qes2du9vaug+obsP6+7D9t577zlVDQAAqzfXcF1Vt80kWL+5u/86Sbr78929tbu/keQ1uXHqx+YkB0ztfrckl82zPgAAGNM8rxZSSV6X5LzuftlU+35T3R6X5BPD8qlJjqyqb6mqg5IcnOQj86oPAADGNs+rhTwgyZOSfLyqzh7anpvkqKo6NJMpHxcl+aUk6e5PVtUpST6VyZVGjnWlEAAAFsncwnV3n5Ftz6N+zwr7HJ/k+HnVBAAA8+QOjQAAMBLhGgAARiJcAwDASIRrAAAYiXANAAAjEa4BAGAkwjUAAIxEuAYAgJEI1wAAMBLhGgAARiJcAwDASIRrAAAYiXANAAAjEa4BAGAkwjUAAIxEuAYAgJEI1wAAMBLhGgAARiJcAwDASIRrAAAYiXANAAAjEa4BAGAkwjUAAIxEuAYAgJEI1wAAMBLhGgAARiJcAwDASIRrAAAYiXANAAAjEa4BAGAkwjUAAIxEuAYAgJEI1wAAMBLhGgAARiJcAwDASIRrAAAYiXANAAAjEa4BAGAkwjUAAIxEuAYAgJEI1wAAMBLhGgAARiJcAwDASIRrAAAYiXANAAAjEa4BAGAkwjUAAIxEuAYAgJEI1wAAMBLhGgAARjK3cF1VB1TVP1TVeVX1yap61tC+Z1W9r6o+OzzfeWivqnpVVZ1fVedW1ffNqzYAAJiHeY5c35DkV7v73knun+TYqrpPkuOSnN7dByc5fVhPkkcmOXh4HJPk1XOsDQAARje3cN3dl3f3x4bla5Kcl2T/JEckOWnodlKSxw7LRyR5Q098OMkeVbXfvOoDAICxrcmc66ralOR+Sf4lyb7dfXkyCeBJ9hm67Z/k0qndNg9tAACwEOYerqtq9yR/leTZ3f3llbpuo623cbxjqurMqjpzy5YtY5UJAAA7ba7huqpum0mwfnN3//XQ/Pml6R7D8xVD++YkB0ztfrckly0/Znef0N2Hdfdhe++99/yKBwCAVZrn1UIqyeuSnNfdL5vadGqSo4flo5O8Y6r9ycNVQ+6f5Oql6SMAALAIdp3jsR+Q5ElJPl5VZw9tz03y4iSnVNVTk1yS5GeGbe9J8qgk5ye5LslT5lgbAACMbm7hurvPyLbnUSfJQ7bRv5McO696AABg3tyhEQAARiJcAwDASIRrAAAYiXANAAAjEa4BAGAkwjUAAIxEuAYAgJEI1wAAMBLhGgAARiJcAwDASIRrAAAYiXANAAAjEa4BAGAkwjUAAIxEuAYAgJEI1wAAMBLhGgAARiJcAwDASIRrAAAYiXANAAAjEa4BAGAkwjUAAIxEuAYAgJEI1wAAMBLhGgAARiJcAwDASIRrAAAYiXANAAAjEa4BAGAkwjUAAIxkh+G6qu5ZVd8yLB9eVc+sqj3mXxoAACyWWUau/yrJ1qr6jiSvS3JQkrfMtSoAAFhAs4Trb3T3DUkel+QV3f2/kuw337IAAGDxzBKuv15VRyU5Osm7hrbbzq8kAABYTLOE66ck+aEkx3f3hVV1UJI3zbcsAABYPLvuqEN3fyrJM6fWL0zy4nkWBQAAi2i74bqqPp6kt7e9uw+ZS0UAALCgVhq5/snh+djh+Y3D8xOTXDe3igAAYEFtN1x398VJUlUP6O4HTG06rqo+mORF8y4OAAAWySwnNO5WVQ9cWqmqH06y2/xKAgCAxbTDExqTPDXJiVV1p2H9S0l+cX4lAQDAYprlaiFnJblvVX1bkuruq+dfFgAALJ4dhuuq+pYkP51kU5JdqypJ0t3mXAMAwJRZpoW8I8nVSc5Kcv18ywEAgMU1S7i+W3c/Yu6VAADAgpvlaiH/XFXfO/dKAABgwc0ycv3AJL9QVRdmMi2kkrQ7NAIAwE3NEq4fOfcqAADgFmCH00KGOzXukeTRw2OPpbs3AgAAN9phuK6qZyV5c5J9hsebquoZ8y4MAAAWzax3aPzB7r42Sarq95N8KMkfzrMwAABYNLNcLaSSbJ1a3zq0rbxT1YlVdUVVfWKq7QVV9bmqOnt4PGpq23Oq6vyq+kxVPXw1bwIAADaCWUau/zzJv1TV24f1xyZ53Qz7vT7JHyV5w7L2l3f3S6Ybquo+SY5M8t1J7prk76rqXt29NQAAsCBmOaHxZUmekuQLSb6Y5Cnd/YoZ9vvHYZ9ZHJHkrd19fXdfmOT8JD8w474AALAhzHJC4/2TfLa7X9Xdr0xyflX94E685tOr6txh2sidh7b9k1w61Wfz0Lateo6pqjOr6swtW7bsRBkAADCuWeZcvzrJV6bWrx3abo5XJ7lnkkOTXJ7kpUP7tuZw97YO0N0ndPdh3X3Y3nvvfTPLAACA8c10QmN3/1fQ7e5vZLa52t+kuz/f3VuHY7wmN0792JzkgKmud0ty2c15DQAAWC+zhOsLquqZVXXb4fGsJBfcnBerqv2mVh+XZOlKIqcmObKqvqWqDkpycJKP3JzXAACA9TLLCPTTkrwqyW9mMlXj9CTH7Ginqjo5yeFJ9qqqzUmen+Twqjp0OM5FSX4pSbr7k1V1SpJPJbkhybGuFAIAwKLZYbju7isyuUzeqnT3Udto3u4l/Lr7+CTHr/Z1AABgo5jlaiH3qqrTl24GU1WHVNVvzr80AABYLLPMuX5Nkuck+XqSdPe5uRkj2QAAcEs3S7j+1u5efnLhDfMoBgAAFtks4frKqrpnhutOV9XjM7lGNQAAMGWWq4Ucm+SEJN9VVZ9LcmGSJ861KgAAWECzXC3kgiQPrardktymu6+Zf1kAALB4tjstpKoeXVUHTjX9apIzqurU4UYvAADAlJXmXB+fZEuSVNVPJvn5JL+Yyd0U/3T+pQEAwGJZKVx3d183LP9Uktd191nd/doke8+/NAAAWCwrheuqqt2r6jZJHpLJbc+X3H6+ZQEAwOJZ6YTGVyQ5O8mXk5zX3WcmSVXdLy7FBwAA32S74bq7T6yq9ybZJ8k5U5v+I8lT5l0YAAAsmhUvxdfdn0vyuWVtRq0BAGAbZrlDIwAAMAPhGgAARjLL7c9TVbsk2Xe6f3dfMq+iAABgEe0wXFfVM5I8P8nnk3xjaO4kh8yxLgAAWDizjFw/K8l3dvdV8y4GAAAW2Sxzri9NcvW8CwEAgEU3y8j1BUneX1XvTnL9UmN3v2xuVQEAwAKaJVxfMjxuNzwAAIBt2GG47u4XrkUhAACw6LYbrqvqFd397Kp6ZyZXB7mJ7n7MXCsDAIAFs9LI9RuH55esRSEAALDothuuu/us4fkDa1cOAAAsLrc/BwCAkQjXAAAwkpnDdVXtNs9CAABg0e0wXFfVD1fVp5KcN6zft6r+ZO6VAQDAgpll5PrlSR6e5Kok6e5zkjxonkUBAMAimmlaSHdfuqxp6xxqAQCAhTbL7c8vraofTtJVdbskz8wwRQQAALjRLCPXT0tybJL9k2xOcuiwDgAATNnhyHV3X5nkiWtQCwAALLQdhuuqOijJM5Jsmu7f3Y+ZX1kAALB4Zplz/TdJXpfknUm+Md9yAABgcc0Srv+zu18190oAAGDBzRKuX1lVz09yWpLrlxq7+2NzqwoAABbQLOH6e5M8KcmP5cZpIT2sAwAAg1nC9eOS3KO7vzbvYgAAYJHNcp3rc5LsMe9CAABg0c0ycr1vkk9X1Udz0znXLsUHAABTZgnXz597FQAAcAswyx0aP7AWhQAAwKLbbriuqjO6+4FVdU0mVwf5r01Juru/be7VAQDAAllp5Hq3JOnuO65RLQAAsNBWulpIr7ANAABYZqWR632q6le2t7G7XzaHegAAYGGtFK53SbJ7JnOsAQCAHVgpXF/e3S9as0oAAGDBrTTneqdGrKvqxKq6oqo+MdW2Z1W9r6o+OzzfeWivqnpVVZ1fVedW1fftzGsDAMB6WClcP2Qnj/36JI9Y1nZcktO7++Akpw/rSfLIJAcPj2OSvHonXxsAANbcdsN1d39hZw7c3f+YZPkxjkhy0rB8UpLHTrW/oSc+nGSPqtpvZ14fAADW2koj1/Owb3dfniTD8z5D+/5JLp3qt3loAwCAhbHW4Xp7tjW/e5vX2a6qY6rqzKo6c8uWLXMuCwAAZrfW4frzS9M9hucrhvbNSQ6Y6ne3JJdt6wDdfUJ3H9bdh+29995zLRYAAFZjrcP1qUmOHpaPTvKOqfYnD1cNuX+Sq5emjwAAwKJY6TrXO6WqTk5yeJK9qmpzkucneXGSU6rqqUkuSfIzQ/f3JHlUkvOTXJfkKfOqCwAA5mVu4bq7j9rOpm+6xF93d5Jj51ULAACshY1yQiMAACw84RoAAEYiXAMAwEiEawAAGIlwDQAAIxGuAQBgJMI1AACMRLgGAICRCNcAADAS4RoAAEYiXAMAwEiEawAAGIlwDQAAIxGuAQBgJMI1AACMRLgGAICRCNcAADAS4RoAAEYiXAMAwEiEawAAGIlwDQAAIxGuAQBgJMI1AACMRLgGAICRCNcAADAS4RoAAEYiXAMAwEiEawAAGIlwDQAAIxGuAQBgJMI1AACMRLgGAICRCNcAADAS4RoAAEYiXAMAwEiEawAAGIlwDQAAIxGuAQBgJMI1AACMRLgGAICRCNcAADAS4RoAAEYiXAMAwEiEawAAGIlwDQAAIxGuAQBgJMI1AACMRLgGAICRCNcAADAS4RoAAEYiXAMAwEh2XY8XraqLklyTZGuSG7r7sKraM8lfJNmU5KIkT+juL65HfQAAcHOs58j1j3b3od192LB+XJLTu/vgJKcP6wAAsDA20rSQI5KcNCyflOSx61gLAACs2nqF605yWlWdVVXHDG37dvflSTI877OtHavqmKo6s6rO3LJlyxqVCwAAO7Yuc66TPKC7L6uqfZK8r6o+PeuO3X1CkhOS5LDDDut5FQgAAKu1LiPX3X3Z8HxFkrcn+YEkn6+q/ZJkeL5iPWoDAICba83DdVXtVlV3XFpO8rAkn0hyapKjh25HJ3nHWtcGAAA7Yz2mheyb5O1VtfT6b+nu/1dVH01ySlU9NcklSX5mHWoDAICbbc3DdXdfkOS+22i/KslD1roeAAAYy0a6FB8AACw04RoAAEYiXAMAwEiEawAAGIlwDQAAIxGuAQBgJMI1AACMRLgGAICRCNcAADAS4RoAAEYiXAMAwEiEawAAGIlwDQAAIxGuAQBgJMI1AACMRLgGAICRCNcAADAS4RoAAEYiXAMAwEiEawAAGMmu613Aotp03LvXuwRYtYte/BPrXQIA3KIZuQYAgJEI1wAAMBLhGgAARiJcAwDASJzQCGxIThpmETlpGDByDQAAIxGuAQBgJMI1AACMRLgGAICRCNcAADAS4RoAAEYiXAMAwEiEawAAGIlwDQAAIxGuAQBgJMI1AACMRLgGAICRCNcAADAS4RoAAEYiXAMAwEiEawAAGIlwDQAAIxGuAQBgJMI1AACMRLgGAICRCNcAADAS4RoAAEYiXAMAwEiEawAAGMmGC9dV9Yiq+kxVnV9Vx613PQAAMKsNFa6rapckf5zkkUnuk+SoqrrP+lYFAACz2VDhOskPJDm/uy/o7q8leWuSI9a5JgAAmMlGC9f7J7l0an3z0AYAABverutdwDK1jba+SYeqY5IcM6x+pao+M/eqWGt7JblyvYu4JarfX+8K2CD8jM2JnzEGfsbmZJ1/xg6cpdNGC9ebkxwwtX63JJdNd+juE5KcsJZFsbaq6szuPmy964BbKj9jMF9+xm7dNtq0kI8mObiqDqqq2yU5Msmp61wTAADMZEONXHf3DVX19CTvTbJLkhO7+5PrXBYAAMxkQ4XrJOnu9yR5z3rXwboy7Qfmy88YzJefsVux6u4d9wIAAHZoo825BgCAhSVcM4qq+soIx7hrVb1the17VNUvz9ofbo2q6nlV9cmqOreqzq6qv62q31vW59CqOm9Yvqiq/mnZ9rOr6hNrWTesharauvT9XVXvrKo9Vrn/4VX1ru20Xz0c++yq+rvxqv6m17rJZyEbj3DNhtHdl3X341foskeSX15Ff7hVqaofSvKTSb6vuw9J8tAkL07ys8u6HpnkLVPrd6yqA4Zj3HstaoV18tXuPrS7vyfJF5IcO+Kx/2k49qHd/dBZd6qq1Z7/dpPPQjYe4Zq5qaoDq+r0YQTt9Kq6+9B+z6r6cFV9tKpetDTqXVWblkbLquq7q+ojwwjAuVV1cCYh4Z5D2x8s679LVb2kqj4+9H/Ger1vWEf7Jbmyu69Pku6+srs/kORLVfWDU/2ekOStU+un5MYAflSSk9eiWFhnH8pwF+hh5Pn9VfW2qvp0Vb25qmrY9oih7YwkP7WaF1jhc/D1VfWyqvqHJL9fVbtV1YnD5+K/VtURQ78dfhaO+O/BSIRr5umPkrxhGEF7c5JXDe2vTPLK7v5vWXaToClPG/ocmuSwTG4wdFySfx9GBX59Wf9jkhyU5H5Trwe3NqclOaCq/q2q/qSqHjy0n5zJaHWq6v5Jruruz07t97bcGBoeneSda1UwrIeq2iXJQ3LTe2ncL8mzk9wnyT2SPKCqbp/kNZn8XPxIkm9f4bA/MjUt5HlD2/Y+B5PkXkke2t2/muR5Sf5++Fz80SR/UFW7ZfWfhWwAwjXz9EO58U/Pb0zywKn2vxyW37J8p8GHkjy3qv53kgO7+6s7eK2HJvnT7r4hSbr7Cze7alhQ3f2VJN+fyS+bW5L8RVX9Qiaj1I+vqttkErKXj0x/IckXq+rIJOcluW7Nioa1dYeqOjvJVUn2TPK+qW0f6e7N3f2NJGcn2ZTku5Jc2N2f7cnl1d60wrGnp4UcP7Rt73MwSf6yu7cOyw9LctxQ2/uT3D7J3bP6z0I2AOGatTTzdR+7+y1JHpPkq0neW1U/toNdajXHh1uq7t7a3e/v7ucneXqSn+7uS5NclOTBSX46k2kgy/1Fkj+OKSHcsn11GAU+MMntctM519dPLW/NjfcCGfOzZfpY104tVyY/q0vh/O7dfd7N+CxkAxCumad/zvCn6CRPTHLGsPzhTD7gM7X9JqrqHkku6O5XZfJnu0OSXJPkjtt5rdOSPG3pxJCq2nOnq4cFU1XfOczJXHJokouH5ZOTvDyTPydv3sbub0/yfzO5Qy7conX31UmemeTXquq2K3T9dJKDquqew/pRq3yp7X0OLvfeJM+Ymud9v+F5tZ+FbADCNWP51qraPPX4lUz+43pKVZ2b5ElJnjX0fXaSX6mqj2RyAtbV2zjezyb5xPAnsu/KZM7aVUk+OFxCaflJHK9NckmSc6vqnCQ/N/o7hI1v9yQnVdWnhp+7+yR5wbDtL5N8d256IuN/6e5ruvv3u/tra1IprLPu/tck52Q7gzxDn//MZJrVu4cTGi/eXt/t2N7n4HK/neS2mXyGfWJYT1b/WcgG4A6NrLmq+tZM/jTXwxzPo7r7iPWuCwBgZ6322oowhu9P8kfDn7++lOQX17keAIBRGLkGAICRmHMNAAAjEa4BAGAkwjUAAIxEuAZYUFXVVfXGqfVdq2pLVb1rlce5qKr22tk+AAjXAIvs2iTfU1V3GNZ/PMnn1rEegFs94Rpgsf1tkp8Ylo/K1O3Lq2rPqvqbqjq3qj5cVYcM7XepqtOq6l+r6s8yufXy0j4/X1Ufqaqzq+rPqmqXtXwzAItOuAZYbG+2wWOTAAABSUlEQVRNcmRV3T6TWyP/y9S2Fyb51+4+JMlzk7xhaH9+kjO6+36Z3FL57klSVffO5I5wD+juQ5NszeSWzQDMyE1kABZYd59bVZsyGbV+z7LND0zy00O/vx9GrO+U5EFJfmpof3dVfXHo/5BMbvL00ck9nnKHJFfM+z0A3JII1wCL79QkL0lyeJK7TLXXNvr2sudpleSk7n7OqNUB3IqYFgKw+E5M8qLu/viy9n/MMK2jqg5PcmV3f3lZ+yOT3Hnof3qSx1fVPsO2PavqwPmXD3DLYeQaYMF19+Ykr9zGphck+fOqOjfJdUmOHtpfmOTkqvpYkg8kuWQ4zqeq6jeTnFZVt0ny9STHJrl4vu8A4Jajurf1l0EAAGC1TAsBAICRCNcAADAS4RoAAEYiXAMAwEiEawAAGIlwDQAAIxGuAQBgJMI1AACM5P8Db3M3laTNGXoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([i for i, _ in enumerate(model_labels)],\n",
    "        [nn_fit_time, cnn_fit_time])\n",
    "plt.title('Model Fitting (& tuning) Times')\n",
    "plt.ylabel('Time in Seconds')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks([i for i, _ in enumerate(model_labels)],\n",
    "           model_labels)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Prediction Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([i for i, _ in enumerate(model_labels)],\n",
    "          [nn_fit_time, cnn_fit_time])\n",
    "plt.title('Model Prediction Times')\n",
    "plt.ylabel('Time in Seconds')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks([i for i, _ in enumerate(model_labels)],\n",
    "           model_labels)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([i for i, _ in enumerate(model_labels)],\n",
    "        [nn_met[0], cnn_met[0]])\n",
    "plt.title('Model Accuracy by Model')\n",
    "plt.ylabel('Accuracy (% 0.0 - 1.0)')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks([i for i, _ in enumerate(model_labels)],\n",
    "           model_labels)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### F1 Scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([i for i, _ in enumerate(model_labels)],\n",
    "        [nn_met[2], cnn_met[2]])\n",
    "plt.title('F1 Average Scores by Model')\n",
    "plt.ylabel('F1 Average (% 0.0 - 1.0)')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks([i for i, _ in enumerate(model_labels)],\n",
    "           model_labels)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Model Assessment\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
